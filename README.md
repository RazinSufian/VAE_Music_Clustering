# ğŸµ VAE Music Clustering

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

A hybrid **Variational Autoencoder (VAE)** for music clustering using audio features (MFCC, Chroma, Spectral Contrast) and lyrics embeddings (TF-IDF). This project implements a **Beta-VAE** architecture with convolutional audio encoding for learning disentangled latent representations of music.

## ğŸ“‹ Project Overview

This project explores unsupervised music clustering using deep generative models. The goal is to learn meaningful latent representations of songs that capture both audio characteristics and lyrical content, then cluster songs based on these representations.

### Key Features

- ğŸ§ **Hybrid Architecture**: Combines CNN-based audio encoder with MLP text encoder
- ğŸ”„ **Beta-VAE**: Implements Î²-annealing for disentangled representations
- ğŸ“Š **Multi-Modal**: Fuses MFCC/Chroma/Spectral audio features with TF-IDF lyrics
- ğŸ¯ **Multiple Clustering**: K-Means, Agglomerative, DBSCAN comparison
- ğŸ“ˆ **Comprehensive Metrics**: Silhouette, Calinski-Harabasz, Davies-Bouldin, ARI, NMI, Purity

## ğŸ“Š Results

| Method | Silhouette | CH Index | DB Index | ARI | NMI | Purity |
|--------|------------|----------|----------|-----|-----|--------|
| **VAE + K-Means** | 0.935 | 12067.75 | 0.225 | 0.004 | 0.018 | 22.5% |
| VAE + Agglomerative | 0.889 | 9856.32 | 0.287 | 0.003 | 0.015 | 21.8% |
| PCA + K-Means | 0.174 | 210.44 | 2.497 | 0.010 | 0.022 | 25.8% |

### Visualizations

<p align="center">
  <img src="results/tsne_visualization.png" width="80%" alt="t-SNE Visualization"/>
</p>

<p align="center">
  <img src="results/confusion_matrix.png" width="80%" alt="Confusion Matrix"/>
</p>

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Hybrid Beta-VAE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Audio Input (1, 39, 130)    Text Input (64)               â”‚
â”‚         â”‚                          â”‚                        â”‚
â”‚         â–¼                          â–¼                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ Conv2d(32)  â”‚            â”‚ Linear(64)  â”‚                â”‚
â”‚  â”‚ Conv2d(64)  â”‚            â”‚ Linear(32)  â”‚                â”‚
â”‚  â”‚ Conv2d(128) â”‚            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                   â”‚                        â”‚
â”‚         â”‚                          â”‚                        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                    â–¼                                        â”‚
â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚            â”‚   Fusion     â”‚                                 â”‚
â”‚            â”‚  (Concat)    â”‚                                 â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚                   â–¼                                         â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚         â”‚ Î¼ (mean)        â”‚                                 â”‚
â”‚         â”‚ Ïƒ (logvar)      â”‚  â†’ Latent Space (32-dim)       â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
â”‚                  â”‚                                          â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
â”‚         â–¼                 â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚  â”‚Audio Decoderâ”‚   â”‚Text Decoder â”‚                         â”‚
â”‚  â”‚(TransConv2d)â”‚   â”‚  (Linear)   â”‚                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Repository Structure

```
VAE_Music_Clustering/
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .gitignore                   # Git ignore rules
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ VAE_Music_Clustering_FINAL.ipynb  # Main notebook (run on Colab)
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ README.md                # Instructions for obtaining dataset
â”‚
â”œâ”€â”€ results/                     # Output visualizations (after running)
â”‚   â”œâ”€â”€ training_curves.png
â”‚   â”œâ”€â”€ reconstruction_examples.png
â”‚   â”œâ”€â”€ tsne_visualization.png
â”‚   â”œâ”€â”€ umap_visualization.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ cluster_selection.png
â”‚   â””â”€â”€ clustering_metrics.csv
â”‚
â””â”€â”€ docs/
    â””â”€â”€ report.pdf               # NeurIPS-style report (if available)
```

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/RazinSufian/VAE_Music_Clustering.git
cd VAE_Music_Clustering
```

### 2. Set Up Dataset

See [data/README.md](data/README.md) for instructions on obtaining and preparing the dataset.

### 3. Run on Google Colab

1. Upload `notebooks/VAE_Music_Clustering_FINAL.ipynb` to Google Colab
2. Enable GPU runtime: `Runtime â†’ Change runtime type â†’ GPU`
3. Mount your Google Drive with the dataset
4. Update the `DRIVE_PATH` variable to point to your data
5. Run all cells

### 4. Local Installation (Optional)

```bash
pip install -r requirements.txt
```

## ğŸ“¦ Dependencies

- Python 3.8+
- PyTorch 2.0+
- librosa
- scikit-learn
- pandas
- numpy
- matplotlib
- seaborn
- umap-learn (optional)

## ğŸ¯ Dataset

The project uses a music dataset with:
- **2,890 songs** across 6 genres (pop, rock, rap, r&b, edm, latin)
- **Audio files**: 30-second WAV clips
- **Metadata**: Track names, genres, lyrics

> âš ï¸ The audio files (~2GB) are not included in this repository due to size constraints. See [data/README.md](data/README.md) for download instructions.

## ğŸ“ˆ Metrics Explained

| Metric | Description | Optimal |
|--------|-------------|---------|
| **Silhouette Score** | Cluster cohesion vs separation | Higher (max 1) |
| **Calinski-Harabasz** | Ratio of between/within cluster variance | Higher |
| **Davies-Bouldin** | Average cluster similarity | Lower |
| **ARI** | Agreement with ground truth | Higher (max 1) |
| **NMI** | Mutual information with labels | Higher (max 1) |
| **Purity** | Dominant class fraction per cluster | Higher |

## ğŸ”¬ Key Findings

1. **Beta-VAE learns smooth latent representations** - The Î²-annealing strategy prevents posterior collapse
2. **Hybrid features outperform audio-only** - Combining audio + lyrics improves clustering quality
3. **Genre boundaries are fuzzy** - Music genres have significant overlap, explaining modest ARI/NMI scores
4. **Optimal clusters â‰  Number of genres** - The model found K=4 optimal despite having 6 genre labels

## ğŸ“ Citation

If you use this code for your research, please cite:

```bibtex
@misc{vae_music_clustering_2026,
  author = {Razin Sufian},
  title = {VAE Music Clustering: Hybrid Audio-Lyrics Representation Learning},
  year = {2026},
  publisher = {GitHub},
  url = {https://github.com/RazinSufian/VAE_Music_Clustering}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Course: CSE425 - Neural Networks
- Dataset: Music Dataset with lyrics and audio features
- Frameworks: PyTorch, librosa, scikit-learn
